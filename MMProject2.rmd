---
title: "Data Science Project -  A Review of the Relationship Between Song Features and Its Relative Popularity With Respect to Time"
author: "Memes and Music: \nRich Gude \nSiwei Yang \nJunhe Zhang \nKrystal Payton"
date: "April 22, 2020"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: true
  pdf_document:
    toc: yes
---

<style type="text/css">
.main-container {
  
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(warning = F, results = T, message = F)
# knitr::opts_chunk$set(warning = F, results = F, message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# 'scipen': integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than 'scipen' digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r basicfcn, include=F}
# use this function to conveniently load libraries and work smoothly with knitting
# can add quietly=T option to the require() function
# note that using this function requires quotes around the package name, as you would when installing packages.
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
# unload/detact package when done using it
# detach_package = function(pkg, character.only = FALSE) { if(!character.only) { pkg <- deparse(substitute(pkg)) } search_item <- paste("package", pkg, sep = ":") while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } }
```

```{r outlierKD2, include = F}
# Fix outliers
outlierKD2 <- function(df, var, rm=FALSE) { 
    #' Original outlierKD functino by By Klodian Dhana,
    #' https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
    #' Modified to have third argument for removing outliers instead of interactive prompt, 
    #' and after removing outlier, original df will not be changed. The function returns the new df, 
    #' which can be saved as original df name if desired.
    #' Check outliers, and option to remove them, save as a new dataframe. 
    #' @param df The dataframe.
    #' @param var The variable in the dataframe to be checked for outliers
    #' @param rm Boolean. Whether to remove outliers or not.
    #' @return The dataframe with outliers replaced by NA if rm==TRUE, or df if nothing changed
    #' @examples
    #' outlierKD2(mydf, height, FALSE)
    #' mydf = outlierKD2(mydf, height, TRUE)
    #' mydfnew = outlierKD2(mydf, height, TRUE)
    dt = df # duplicate the dataframe for potential alteration
    var_name <- eval(substitute(var),eval(dt))
    na1 <- sum(is.na(var_name))
    m1 <- mean(var_name, na.rm = T)
    par(mfrow=c(2, 2), oma=c(0,0,3,0))
    boxplot(var_name, main="With outliers")
    hist(var_name, main="With outliers", xlab=NA, ylab=NA)
    outlier <- boxplot.stats(var_name)$out
    mo <- mean(outlier)
    var_name <- ifelse(var_name %in% outlier, NA, var_name)
    boxplot(var_name, main="Without outliers")
    hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
    title("Outlier Check", outer=TRUE)
    na2 <- sum(is.na(var_name))
    cat("Outliers identified:", na2 - na1, "\n")
    cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "\n")
    cat("Mean of the outliers:", round(mo, 2), "\n")
    m2 <- mean(var_name, na.rm = T)
    cat("Mean without removing outliers:", round(m1, 2), "\n")
    cat("Mean if we remove outliers:", round(m2, 2), "\n")
    
    # response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
    # if(response == "y" | response == "yes"){
    if(rm){
        dt[as.character(substitute(var))] <- invisible(var_name)
        #assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
        cat("Outliers successfully removed", "\n")
        return(invisible(dt))
    } else {
        cat("Nothing changed", "\n")
        return(invisible(df))
    }
}

```

# Executive Summary:



# Purpose:

The purpose of this study it to analyse the affect of music attributes, such as tempo, key, mode, etc, on the popularity of songs with respect to time.  Specifically, the SMART question for this study is: Does the key, valence, tempo, or other musical attributes changes between popular songs, and not popular songs for contrast, in the 1960's versus songs from the early 2000's?

The methodology by which this will be accomplished is to analyze song attribute data collected from Spotify using their application programming interface (API).  This attribute data collects the following features for every song, or "track", under review: track, artist, key, mode, valence, tempo, "energy", "liveness", and "danceability".  The popularility of each song will be a binary attribute: A song will be considered popular if it appears in the Billboard Hot 100, a weekly top list of the popular tracks from each week measured by Billboard Magazine.  Billboard Magazine is the widely considered standard for song popularity and has existed since the 1960s through today and, so, represents a consistent standard for measuring song popularity through time.

# A Discussion of Basic Music Theory

Music, as an art, has a long and varied history depending on the era and geographical space in which an individual may be concerned.  While the purpose of this study is to identify the change of popular music, at least over a short period since what is 50 years to the entire timeline of the human species over which music in some form is sure to have been evident, the entire history of what music is composed and how it is written or expressed will not be discussed herein.  Instead, this study is focused on contemporary, American-produced songs, and so, certain objective measurements of song qualities, namely tempo, key, and mode, can be used to compare and contrast songs both across the musically spectrum, from say jazz to rock-and-roll, and through time.

Tempo, key, and mode are relatively basic concepts in music theory.  The beat is the basic unit of time in music, the pace at which the music pulses; it is, essentially, when a listener would tap their toe during a song.  **Tempo** is the speed or pace of a given song and is often measured beats per minute.  Certain genres of songs are defined by high tempos, like electric-dance music (EDM), but most genres vary considerably in their tempo.  Pitch is the audio frequency at which individual notes within the song are heard by the listener.  In general terms, the **key** of a song is average pitch of a song, or the pitch around which a song fluctuates; performing a song in a higher key means that all of the notes of a song are increased at a level commiserate with the change in key (a major key change from "C'" to "D", one pitch, would change the pitch of all notes in the song up pitch as well).  Along the same concept as key, **mode** is the interval at which pitches are expressed in a song and is expressed as either "minor" or "major".  The key and mode are often expressed together when describing the pitch qualities of a song, such as "F major" or "D minor".  From an audio perspective, "major" keys are more often associated with and evoke happy or bright melodies, whereas "minor" keys may sound melancholic.

The concepts discussed here are general introduction to the features that will be discussed as part of this study's dataset, and the format herein does not support audio examples, which would be necessary for any comprehensive understanding of music theory.  Additional discussion of tempo, key, and mode, with audio examples for the differences between keys and modes, can be found [here](https://www.youtube.com/watch?v=rgaTLrZGlk0).

# Data Selection:

As identified in the methodology statement, the data in this study is pulled from two corporate sources, Spotify Technology S.A. (Spotify) and the Billboard-Hollywood Media Group.  Spotify is a popular online streaming service for music, videos, and podcasts.  Spotify provides an "Audio Analysis" of a musical tracks that describes the structure of the tracks and its musical content, including tempo, key, and mode, discussed above, in addition to more sophisticated musical metrics relating multiple core concepts of music.  The advance metrics that will be tracked from Spotify Audio Analysis in this study are valence, "danceability", "energy", and "liveness"; these metrics are discussed further below.  The Billboard-Hollywood Media Group owns and produces the "Billboard" magazine.  This publication is famous for the Billboard Hot 100 list, a weekly-published list that identifies the most popular, American songs of the week, based on sales and digital downloads and streams.  The Billboard Hot 100 have been in publication since 1958 and establishes an objective standard for identifies popular songs for the purposes of this study.

Based on the source from which popular songs are determined, the conclusions of this study should only apply to songs produced or with a large-commerical release in the United States of America.  Song features for popular songs based on similar metrics of sales and digital views from other countries may vary from the results reported herein.

The data analyized herein was pulled from the Kaggle database website.  The specific dataset can be found [here](https://www.kaggle.com/theoverman/the-spotify-hit-predictor-dataset).

# Data Background:

As stated previously, the Spotify Audio Analysis records multiple features for each track in its extensive collection of music titles.  Some of these features, such as tempo, key, and mode, have strict definitions within the music community and are, otherwise, clear, quantifiable variables (e.g., tempo is measured in beats per minute).  Other features do not have strict definitions within the music community and/or do not have a clear, quantifiable standard that can be measured within each track.  The following features are ranked in Spotify's analyses on a scale of 0 to 1 and will be considered for analysis in this study: [^1]
- **Valence** describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).  For perspective: from the 2000's data set, one popular song with a high valence (0.965) is OutKast's [Hey Ya](https://open.spotify.com/track/2PpruBYCo4H7WOBJ7Q2EwM?si=3b7dll0ITZ-H5FsIu-qGig), while a song with low valence (0.0356) is deadmau5's [Strobe](https://open.spotify.com/track/31NiyZrUd1r4icY7xkvnWv?si=przVh9EjRgG-oyH5rInY9A).
- **Danceability** describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. For perspective: from the 2000's data set, one popular song with a high danceability (0.956) is Nelly's [Hot in Herre](https://open.spotify.com/track/04KTF78FFg8sOHC1BADqbY?si=i8f_wIreTsu34rIpSX4PDA), while a song with low danceability (0.0356) is Venom's [Black Metal](https://open.spotify.com/track/3yNoEJifUJdly8ucYoWRwl?si=15rDImzOTkSfJlpggbrPLw). 
- **Energy** represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. For perspective: from the 2000's data set, one popular song with a high energy (0.991) is Fatboy Slim's [The Rockafeller Skank](https://open.spotify.com/track/7mCQK9YB25WZw1saUjfL4e?si=46Rwt-TMQgusLo_Wjm3o0g), while a song with low energy (0.0013) is Alvin Curran's [Inner Cities II](https://open.spotify.com/track/4De0j0rVNmezk0EXPzOtwZ?si=ShNPfVWrQfKzZPiBlxKS-g).
- **Liveness** detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. For perspective: from the 2000's data set, one popular song with a high liveness (0.959) is Metallica's [No Leaf CLover - Live](https://open.spotify.com/track/0n4AllHzf3ma4ki20Y9h00?si=d3-JKQO9SOeTVxMzNhOYYQ), while any studio-produced song would have a low liveness.

The full analysis of these features, namely the methods or calculations by which their values are determined, are not released by Spotify, potentially due to intellectual property reasons.

The Billboard Hot 100 has several component charts that contribute to the overall calculation of the Hot 100 each week. The most significant components are: [^2]
- **Hot 100 Airplay**: (per Billboard) approximately 1,000 stations, "composed of adult contemporary, R&B, hip hop, country, rock, gospel, Latin and Christian formats, digitally monitored twenty-four hours a day, seven days a week. Charts are ranked by number of gross audience impressions, computed by cross-referencing exact times of radio airplay with Arbitron listener data." 
- **Hot Singles Sales**: (per Billboard) "the top selling singles compiled from a national sample of retail store, mass merchant and internet sales reports collected, compiled, and provided by Nielsen SoundScan." The chart is released weekly and measures sales of physical commercial singles. With the decline in sales of physical singles in the US, many songs that become number one on this chart often do not even chart on the Hot 100.
- **Digital Songs**: Digital sales are tracked by Nielsen SoundScan and are included as part of a title's sales points.
- **Streaming Songs**: a collaboration between Billboard, Nielsen SoundScan and National Association of Recording Merchandisers which measures the top streamed radio songs, on-demand songs and videos on leading online music services.

From these varied and independent sources, the Billboard Hot 100 represents a nuetral and storied arbiter of the objective popularity of songs from 1958 thorugh the present, including all songs to be evaluated from the 1960s and early 2000s.

# Data Preprocessing

The Spotify Audio Analysis stores up to 42 music features for each track.  For the purposes of this study, only the following variables will be analyzed and reviewed:

``` {r DataImport, include = F, results = F}
loadPkg('tidyverse')

# Import 1960's and 2000's data as separate dataframes
data1960 <- subset(data.frame(read_csv('dataset-of-60s.csv')), select = c('track', 'artist', 'tempo', 'key', 'mode', 'valence', 'danceability', 'energy', 'liveness', 'target'))
data2000 <- subset(data.frame(read_csv('dataset-of-00s.csv')), select = c('track', 'artist', 'tempo', 'key', 'mode', 'valence', 'danceability', 'energy', 'liveness', 'target'))
# Provide a summary of the columns and data within the data
summary(data2000)
length((which(data2000$target == 1)))
nrow(subset(data2000,target == 0))
length(data1960$target[data1960$target == 1])
length(data1960$target[data1960$target == 0])
```

**Track Variables of Interest:**

1. Track: the name of the track
2. Artist: the name of the artist
3. Tempo: a float value for the beats per minute of the song 
4. Key: an integer mapping of the standard pitch-class notation where: 0 = C key, 1 = C*#*/D*b*, 2 = D, and so on in rising key fashion up to 11 = B key.
5. Mode: an integer mapping for major (1) and minor (0) keys
6. Valence: a float value between 0 and 1 for the relative valence of the track (discussed in the Data Background)
7. Danceabilty: a float value between 0 and 1 for the relative danceability of the track (discussed in the Data Background)
8. Energy: a float value between 0 and 1 for the relative energy of the track (discussed in the Data Background)
9. Liveness: a float value between 0 and 1 for the relative liveness of the track (discussed in the Data Background)

In preprocessing the data, all of the variables from the Spotify data not listed above were eliminated from the study dataset.

The final feature, **Target**, was computed from the collective data from Billboard's Hot 100 list.  Any track listed in the Billboard Hot 100 during the respective decade from which a track was released is given a value of 1, and any track not list at any point in the Billboard Hot 100 is given a 0.

This study will examine the change in music metrics affecting popularity with respect to time.  For this purpose, this study will analyze two datasets, one with songs released during the 1960s, containing `r nrow(data1960)` songs, and the other with songs released from the 2000s, containing `r nrow(data2000)` songs.  Each dataset is composed of an equal number of popular and not popular songs, `r nrow(subset(data2000,target == 1))` popular and not popular songs from the 2000s and `r nrow(subset(data1960,target == 1))` popular and not popular songs from the 1960s.  For every song that appears in the Billboard Hot 100 list from their respective decade (with a target value of 1), another song from the same decade, not appearing in the Hot 100 was chosen to fill in the dataset for analytics and review.

A summary of the variables and their values from the entire 2000's and 1960's datasets are presented below:

``` {r DataSummary1}
# Provide a summary of the columns and data within the data
print('A Summary of the 2000\'s Dataset:')
summary(data2000)

print('A Summary of the 1960\'s Dataset:')
summary(data1960)
```

# Variable Anaylsis and Approach

The purpose of this study is to identify any link or lackthereof between the popularity of a song and seven other factors, tempo, key, mode, valence, danceability, energy, and liveness, based on track metric data computed from Spotify.  A cursory review of the song feature values for just popular between the two decades shows a difference in the mean values for multiple song features.  From the 1960's to the early 2000's, the mean valence noticeably decreases while the mean danceability and energy values noticeably increase.

``` {r DataSummary2}
# Provide a summary of the columns and data within the data
print('A Summary of the Popular 2000\'s Tracks:')
summary(subset(data2000, target == 1))

print('A Summary of the Popular 1960\'s Tracks:')
summary(subset(data1960, target == 1))
```

# K-Nearest Neighbor - Juhne

The project goal is to explore which features determine whether a song is popular or not. K-Nearest Neighbor is a good option to apply on this dataset. Since K-Nearest Neighbor algorithms use distance function to measure distance among each data point, make sure that every predictor has same unit is very important. 

From the previous EDA section it showed that **tempo, key and mode** have much greater mean with other predictors. Therefore, in order to make the most accuary K-Nearest Neighbor model scale the data using Z-score is necessary.

On the other hand, since the K-Nearest Neighbor algorithm highly depend on distance function. Cleaning the categorical features like **track and artist** is also very important.
 
From the scaled dataset, notice that **tempo** for 2000 data is smaller than 1960 data in unit factor, the **mode and valence** value range for 2000 data are more spread than 1960 data showing that musice in 2000 have more varieties than music in 1960. However, the 2000s' musics are in general have more **energy** than 1960's musics. 

## K-Nearest Neighbor Scaling

### scale (data 2000)

```{r scale-data-junhe-20}
# scale tempo ~ liveness
df.scaled.20 <- as.data.frame(scale(data2000[3:9], center = TRUE, scale = TRUE))
# factor strings
# df.scaled.20$track <- as.factor(data2000$track)
# df.scaled.20$artist <- as.factor(data2000$artist)
df.scaled.20$target <- as.factor(data2000$target)

summary(df.scaled.20)
```

### scale (data 1960)

```{r scale-data-junhe-60}
# scale tempo ~ liveness
df.scaled.60 <- as.data.frame(scale(data1960[3:9], center = TRUE, scale = TRUE))
# factor strings
# df.scaled.20$track <- as.factor(data2000$track)
# df.scaled.20$artist <- as.factor(data2000$artist)
df.scaled.60$target <- as.factor(data1960$target)

summary(df.scaled.60)
```

## K-Nearest Neighbor Correlation Matrix

### KNN-correlation matrix of (data 2000)

Before building KNN model, in order to preventing high collinearity between each predictor, it is also necessary to check th correlation between each predictors. From the correlation matrix for 2000s dataset and 1960s dataset, all predictors are not highly related to each other.  

```{r KNN-correlation-junhe-20}
loadPkg('psych')
#pairs(df.scaled.20)
pairs.panels(data2000, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB", # set histogram color, can use "#22AFBB", "red",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )

```

### KNN-correlation matrix of (data 1960)

```{r KNN-correlation-junhe-60}

#pairs(df.scaled.60)
pairs.panels(data1960, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB", # set histogram color, can use "#22AFBB", "red",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
#unloadPkg('psych')
```

## K-Nearest Neighbor Spliting data into train test subsets

### KNN split data into train test subsets (data 2000)

Since datas are very precious, it is always a good idea to split the original dataset into train and test subsets. Use training data set to fit KNN model and use test dataset to test the accuracy our the model is the best way to utilize the dataset. Split the original data into 4:1 train and test subset.

```{r train-test-junhe-20}
# split data into train test subset, ratio 4:1, seed 42
seed <- 42
## set the seed to make the partition reproducible
set.seed(seed)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(data2000))
# scale tempo ~ liveness
# df.scaled.20 <- as.data.frame(scale(data2000[3:9], center = TRUE, scale = TRUE))
# df.scaled.20$target <- as.factor(data2000$target)
summary(df.scaled.20)

dat20_sample <- sample(2, nrow(df.scaled.20), replace=TRUE, prob=c(0.80, 0.20))

```

### KNN split data into train test subsets (data 1960)

```{r train-test-junhe-60}
# split data into train test subset, ratio 4:1, seed 42
seed <- 42
## set the seed to make the partition reproducible
set.seed(seed)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(data1960))
# scale tempo ~ liveness
# df.scaled.20 <- as.data.frame(scale(data2000[3:9], center = TRUE, scale = TRUE))
# df.scaled.20$target <- as.factor(data2000$target)
summary(df.scaled.60)

dat60_sample <- sample(2, nrow(df.scaled.60), replace=TRUE, prob=c(0.80, 0.20))

```

## K-Nearest Neighbor Seperate target variable

### KNN seperate target variable y and predictors X (data 2000)

In order to test accuracy of the fitted models, spliting target variable **target** (1 stands for popular, 0 stands for not popular) variable from the predictors is also necessary.

```{r y-X-junhe-20}
train.X.20 <- df.scaled.20[dat20_sample==1, 1:7]
train.y.20 <- df.scaled.20[dat20_sample==1, 8]
test.X.20 <- df.scaled.20[dat20_sample==2, 1:7]
test.y.20 <- df.scaled.20[dat20_sample==2, 8]
#dim(test.X.20)[1]/dim(df.scaled.20)[1]
summary(test.X.20)
dim(train.X.20)
```

### KNN seperate target variable y and predictors X (data 1960)

```{r y-X-junhe-60}
train.X.60 <- df.scaled.60[dat60_sample==1, 1:7]
train.y.60 <- df.scaled.60[dat60_sample==1, 8]
test.X.60 <- df.scaled.60[dat60_sample==2, 1:7]
test.y.60 <- df.scaled.60[dat60_sample==2, 8]
#dim(test.X.60)[1]/dim(df.scaled.60)[1]
summary(test.X.60)
dim(train.X.60)
```

## K-Nearest Neighbor helper function to choose best k value

This helper function apply K-Nearest Neighbor model function from **class** library, then build confusion matrix using the predicted target value with the test target value. Finally, using the formula **TP/(TP+NP)** to calculate accuracy of the fitted KNN model with given K value. 

Accuracy is a very important factor to determine the goodness of a fitted KNN model. On the other hand, because of high k-value indicates high precision and high cost on computation, carefully determine the appropriate k-value in order to manage best the trade-off between precision and computation cost is very important. In other word, using the exhaust approach to test a series of k-values and find the most appropriate k-value is the best way to do.

```{r checkK-helper-junhe}
# load class package for knn
loadPkg('class')
# function to selection best k #
chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k) #,                #<- number of neighbors considered
                  # use.all = TRUE)       #<- control ties between class assignments
                                        #   If true, all distances equal to the kth 
                                        #   largest are included
  
  tab = table(class_knn, val_class)
  
  # Calculate the accuracy.
  accu = sum(tab[row(tab) == col(tab)]) / sum(tab)                         
  cbind(k = k, accuracy = accu)
}
```

## K-Nearest Neighbor helper function to selection best combination of features with highest accuracy

In order to build the best KNN model with the given datasets to predict whether a music is popular or not. It is necessary to use exhaust approach to build model with all combinations of predictors and decide which combination of predictors can generate the most accurate model.

The **featureSelectionKNN** helper function applies **combn** function which helps generate a list of **n Choose i**, where n stands for number of predictors, i stands for number of predictors we want to consider in each iteration from i to n. Within each iteration, apply **chooseK** function to determine the best k-value for this combination of predictors. Then store the model with the highest accuracy into the result dataframe.

The time complexity for this algorithm is **[(7 Choose 1) times (21-3) times O(knn_function)] +...+ [(7 Choose 7) times (21-3) times O(knn_function)]**. Iterating from **7 Choose 1 to 7 Choose 7**

```{r featureSelection-junhe}
#features <- combn(names(train.X.20),3)
#features[,1]
#head(train.X.20[,features[,1]])
featureSelectionKNN <- function(train.X, test.X, train.y, test.y){
  res <- data.frame(k = 0, accuracy = 0, features = '')
  for(i in 3:dim(train.X)[2]-1){
    features <- combn(names(train.X),i)
    for(j in 3:dim(features)[2]-1){
      knn_different_k = sapply(seq(3, 21, by = 2),  #<- set k to be odd number from 3 to 21
                         function(x) chooseK(x, 
                                             train_set = train.X[,features[,j]],
                                             val_set = test.X[,features[,j]],
                                             train_class = train.y,
                                             val_class = test.y))
      
      knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])
      
      new.df = data.frame(k = knn_different_k[order(-knn_different_k$accuracy),][1,1],
                          accuracy = knn_different_k[order(-knn_different_k$accuracy),][1,2],
                          features = paste(features[,j],collapse=" ")
                          )
      res = rbind(res, new.df)
    }
    #print(dim(features)[2])
  }
  res
}

```

## KNN feature selection (data 2000)

```{r feature-selection-junhe-20}
features.20 = featureSelectionKNN(train.X.20, test.X.20, train.y.20, test.y.20)
# head(test[order(-test$accuracy),])
f.20 <- data.frame(features.20[order(-features.20$accuracy),3])
head(f.20)
```

From the above result, the best KNN model for 2000s data after feature selection has accuracy equal to 0.75 with k-value equal 15 and 5 features which are **tempo, valence, danceability, energy and liveness**.

The alternative option is the second best KNN model with accuracy equal to 0.75 as same as the best model but with lower k-value which equals 13, and 6 instead of 5 features which are **tempo, mode, valence, danceability, energy and liveness**. However, high k-value can cause expensive computation cost and second best KNN model seems to be better than the best KNN model in the list, we want to minimize the number of involved predictors to be able to explore the most important factors that decide whether a music is popular or not in 2000s.

## KNN feature selection (data 1960)

```{r feature-selection-junhe-60}
features.60 = featureSelectionKNN(train.X.60, test.X.60, train.y.60, test.y.60)
# head(test[order(-test$accuracy),])
f.60 <- data.frame(features.60[order(-features.60$accuracy),3])
f.60
```

From the above result, the best KNN model for 1960s data after feature selection has accuracy equal to 0.68 with k-value equal 19 and only 4 features which are **mode, valence, energy and liveness**.

The alternative option is the second best KNN model with accuracy equal to 0.68 as same as the best model but with higher k-value which equals 21, and 5 instead of 4 features which are **key, mode, valence, danceability, energy**. This time the second best KNN model loses on both k-value and number of predictors. So, we choose the best model without doubt as our final KNN model for 1960s dataset.

In conclusion, comparing the best model for 1960s dataset and 2000s dataset, the important features to determine whether a music is popular has changed from **mode, valence, energy and liveness** in 1960s to **tempo, valence, danceability, energy and liveness** in 2000s. In other word, people in 1960s took **mode, valence, energy and liveness** these four music elements as the most important feature to determine whether a music is good or not, and has changed in 2000s to **tempo, valence, danceability, energy and liveness** these five music elements. People still think **valence, energy and liveness** are important factors but no longer took **mode** as an important factor. Moreover, took **tempo and danceability** as two new important factors.

##Visualize k-values in the best KNN model (data 2000)

Build the KNN model using 2000s dataset with the best subset of features and check correctness our above **featureSelectionKNN** result. Notice that the best k-value among 1 through 81 is still 15 which is as same as the result we get from **featureSelectionKNN** function. On the other hand, k-value equal 15 is also the ankle value of the k-values series which is the best k-value we are looking for.

```{r KNN-junhe-20}
# features selected by features selection function, with the best accuracy
best_features.20 <- c('tempo', 'valence', 'danceability', 'energy', 'liveness')

knn_different_k = sapply(seq(1, 81, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = train.X.20[,best_features.20],
                                             val_set = test.X.20[,best_features.20],
                                             train_class = train.y.20,
                                             val_class = test.y.20))

# Reformat the results to graph the results.
#str(knn_different_k)
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])

# Plot accuracy vs. k.
# install.packages("ggplot2")
loadPkg('ggplot2')

ggplot(knn_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
#summary(pima$type)[2]/dim(pima)[1]
#head(knn_different_k[order(knn_different_k$accuracy),])
#as.data.frame(knn_different_k[order(-knn_different_k$accuracy),])[1,2]
```

##Visualize k-value trend in the best KNN model (data 1960)

Build the KNN model using 1960s dataset with the best subset of features and check correctness our above **featureSelectionKNN** result. Notice that the best k-value among 1 through 81 is still 19 which is as same as the result we get from **featureSelectionKNN** function. On the other hand, k-value equal 19 is also the ankle value of the k-values series which is the best k-value we are looking for.

The correctness of all the results has now been proved

```{r KNN-junhe-60}
# features selected by features selection function, with the best accuracy
best_features.60 <- c('mode', 'valence', 'energy', 'liveness')

knn_different_k = sapply(seq(1, 81, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = train.X.60[,best_features.60],
                                             val_set = test.X.60[,best_features.60],
                                             train_class = train.y.60,
                                             val_class = test.y.60))

# Reformat the results to graph the results.
#str(knn_different_k)
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])

# Plot accuracy vs. k.
# install.packages("ggplot2")
loadPkg('ggplot2')

ggplot(knn_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
#summary(pima$type)[2]/dim(pima)[1]
#head(knn_different_k[order(knn_different_k$accuracy),])
#as.data.frame(knn_different_k[order(-knn_different_k$accuracy),])[1,2]
```


# Logit Regression - Siwei
(For each test, write down the following: What the test says/Why are we performing, the assumptions of test, the math behind (why I trust the results), and discussion of conclusion - **NAMELY HOW THE VALUES OR FEATURES OR PROBABILITIES CHANGE BETWEEN THE TWO DATASETS as that is our purpose for this study**. Another good method is for each of the tests below, conduct all of the indiviudal tests that were performed in each weekly Rstudio document for said test (e.g., logit - our point is to impress with the data discussion and fill out a 10-page report))

```{r LogReg-Siwei}
data1960$track <- factor(data1960$track)
data1960$artist <- factor(data1960$artist)
data1960$key <- factor(data1960$key)
data1960$mode <- factor(data1960$mode)
data1960$target <- factor(data1960$target)
```

```{r LogReg-Siwei}
data1960Logit_1 <- glm(target ~ tempo, data = data1960, family = "binomial")
data1960Logit_1
```

We can see the summary of the logit model here:  
```{r logitSummary-Siwei}
summary(data1960Logit_1)
```

```{r LogReg-Siwei}
data1960Logit_2 <- glm(target ~ tempo+valence, data = data1960, family = "binomial")
data1960Logit_2

summary(data1960Logit_2)
```

```{r LogReg-Siwei}
data1960Logit_3 <- glm(target ~ tempo+valence+danceability, data = data1960, family = "binomial")
data1960Logit_3

summary(data1960Logit_3)
```

```{r LogReg-Siwei}
data1960Logit_4 <- glm(target ~ tempo+valence+danceability+energy, data = data1960, family = "binomial")
data1960Logit_4

summary(data1960Logit_4)
```

```{r LogReg-Siwei}
data1960Logit_5 <- glm(target ~ tempo+valence+danceability+energy+liveness, data = data1960, family = "binomial")
data1960Logit_5

summary(data1960Logit_5)
```

We can also easily obtain the growth/decay factors for each explanatory variables. Notice that these factors apply to the odds-ratio, not the odds of being accepted. Nonetheless, these growth and decay factors are very useful in our analysis. The factors are the exponentials of the coefficients:   

```{r growthDecayFactors, LogReg-Siwei}
expcoeff = exp(coef(data1960Logit_5))
expcoeff
```

```{r LogReg-Siwei}
data2000$track <- factor(data2000$track)
data2000$artist <- factor(data2000$artist)
data2000$key <- factor(data2000$key)
data2000$mode <- factor(data2000$mode)
data2000$target <- factor(data2000$target)
```


```{r LogReg-Siwei}
data2000Logit_1 <- glm(target ~ tempo, data = data2000, family = "binomial")
summary(data2000Logit_1)
```

```{r LogReg-Siwei}
data2000Logit_2 <- glm(target ~ tempo+valence, data = data2000, family = "binomial")
summary(data2000Logit_2)
```

```{r LogReg-Siwei}
data2000Logit_3 <- glm(target ~ tempo+valence+danceability, data = data2000, family = "binomial")
summary(data2000Logit_3)
```

```{r LogReg-Siwei}
data2000Logit_4 <- glm(target ~ tempo+valence+danceability+energy, data = data2000, family = "binomial")

summary(data2000Logit_4)
```

```{r LogReg-Siwei}
data2000Logit_5 <- glm(target ~ tempo+valence+danceability+energy+liveness, data = data2000, family = "binomial")

summary(data2000Logit_5)
```

We can also easily obtain the growth/decay factors for each explanatory variables. Notice that these factors apply to the odds-ratio, not the odds of being accepted. Nonetheless, these growth and decay factors are very useful in our analysis. The factors are the exponentials of the coefficients:   

```{r growthDecayFactors, LogReg-Siwei}
expcoeff = exp(coef(data2000Logit_5))
expcoeff
```

(Linear Regression but with non-linear modeling - our target is binary so this is good)

# Feature Selection/Model selection - Krystal
(For each test, write down the following: What the test says/Why are we performing, the assumptions of test, the math behind (why I trust the results), and discussion of conclusion - **NAMELY HOW THE VALUES OR FEATURES OR PROBABILITIES CHANGE BETWEEN THE TWO DATASETS as that is our purpose for this study**. Another good method is for each of the tests below, conduct all of the indiviudal tests that were performed in each weekly Rstudio document for said test (e.g., logit - our point is to impress with the data discussion and fill out a 10-page report))

Suggestion: Include an analysis and discussion of why certain variables are best (find and discuss computing time for instance)

# Summary of Results



---
[^1] Taken from [Spotify for Developers Web Services Page](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)
[^2] From Molanphy, Chris (August 1, 2013). "How The Hot 100 Became America's Hit Barometer". Published by NPR.

















